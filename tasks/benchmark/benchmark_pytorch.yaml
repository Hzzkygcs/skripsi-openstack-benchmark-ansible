- name: Set PyTorch phoronix base directory  # specific for running phoronix as root  (become: true)
  set_fact:
    pytorch_profile_folder: '/var/lib/phoronix-test-suite/test-profiles/pts/{{ pytorch_phoronix_test_version }}'

- debug:
    msg: "env DISPLAY=:0 ./phoronix-test-suite install {{ pytorch_phoronix_test_version }} 2>&1"

- name: install phoronix pytorch
  command: "env DISPLAY=:0 ./phoronix-test-suite install {{ pytorch_phoronix_test_version }} 2>&1"
  become: true
  args:
    chdir: "{{ phoronix_folder }}"
  register: pytorch_install_result
- set_fact:
    cleaned_pytorch_install_result: "{{ pytorch_install_result.stdout | regex_replace('\x1B\\[[0-9;]*[mK]', '') }}"
- name: write pytorch install logs
  delegate_to: localhost
  copy:
    content: "{{ cleaned_pytorch_install_result }}"
    dest: "{{benchmark_result_folder}}/pytorch_install_result.txt"


# Phoronix did validation for test-definition options that contains substring "nvidia" and "cuda". However,
# They did the validation by checking the GPU model of current system, check if the model name contains "nvidia"
# However this is not the case for Google Cloud PLatform's GPU which is Nvidia but the model name is "Tesla T4 15GB",
# no nvidia substring in it. That issue doesn't allow us to choose between GPU vs CPU.
# (See https://github.com/phoronix-test-suite/phoronix-test-suite/issues/771 )
- name: replace PyTorch test-definition.xml to bypass Phoronix's faulty Nvidia validation
  copy:
    src: ./test-profiles/pytorch-test-definition.xml
    dest: "{{ pytorch_profile_folder }}/test-definition.xml"


- name: Start nvidia-smi-track.py for PyTorch
  become: true
  shell: >-
    {{ nvidia_track_py_script }} START "{{base_path}}/track_result_nvidia_smi_pytorch.txt"
  async: 10000
  poll: 0


- name: run pytorch benchmark  # Will run for about 35 minutes
  async: 1000000
  poll: 5
  become: true
  ignore_errors: yes
  expect:
    timeout: 1000000
    command: "{{ prime_run }} env FORCE_TIMES_TO_RUN=3 DISPLAY=:0 {{ phoronix_test_suite }} benchmark {{ pytorch_phoronix_test_version }} 2>&1"
    responses:
      'Would you like to save these test results': 'n'
      'Batch Size:': '1,2,4,6'
      'Model:': '4'
      'Device:': 'gpu'
  register: pytorch_benchmark_result



- name: Stop nvidia-smi-track.py for PyTorch
  shell: >-
    {{ nvidia_track_py_script }} STOP "{{base_path}}/track_result_nvidia_smi_pytorch.txt"
  register: result

- name: "write nvidia-smi-track.py for PyTorch"
  delegate_to: localhost
  copy:
    content: "{{ result.stdout }}"
    dest: "{{benchmark_result_folder}}/nvidia_smi_pytorch.txt"

# 1: CPU
# 2: gpu
# 3: Test All Options
# ** Multiple items can be selected, delimit by a comma. **
# Device:

#  1: 1
#  2: 16
#  3: 32
#  4: 64
#  5: 256
#  6: 512
#  7: Test All Options
#  ** Multiple items can be selected, delimit by a comma. **
#  Batch Size:

#  1: ResNet-50
#  2: ResNet-152
#  3: Efficientnet_v2_l
#  4: Test All Options
#  ** Multiple items can be selected, delimit by a comma. **
#  Model:


- set_fact:
    cleaned_pytorch_benchmark_result: "{{ pytorch_benchmark_result.stdout | regex_replace('\x1B\\[[0-9;]*[mK]', '') }}"
- name: write pytorch benchmark logs
  delegate_to: localhost
  copy:
    content: "{{ cleaned_pytorch_benchmark_result }}"
    dest: "{{benchmark_result_folder}}/pytorch_benchmark_result.txt"
